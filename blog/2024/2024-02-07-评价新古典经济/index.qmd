---
title: "经济学研究范式的传统与变革"
description: ChatGPT不但对人类生产方式、生活方式与思维方式产生深刻影响，也正在推动经济学研究范式的变革。
author:
- name: Jason ZHOU
  orcid: 0000-0001-7685-5337
date: 2024-02-06
categories:
  - 教学材料
  - "2024"
  - GPT生产
keywords:
  - 经济学发展
  - 文献综述
image: "projec.webp"
subtitle: >
  从 ChatGPT 对经济学范式的潜在影响中发现经济学的传统
links:
- icon: journal-text
  name: Quarto Docs
  url: https://quarto.org/docs/websites/
filters:
   - include-code-files
code-annotations: below
df-print: paged

---

## 写在前面

这篇文章是洪永淼和汪寿阳两位老师2024 年发表在 《计量经济学报》第1期的一篇讨论 ChatGPT 与大模型可能会对经济学研究范式产生潜在影响的综述性文章。在阅读之后，给我最大的启发在于：
- 传统经济学存在不同的限制条件，而了解这些限制条件对于正确的使用它们分析问题、解释问题有很大帮助。
- 传统经济学之所以呈现出“大树形态”正是因为不同学派对已有研究和学派的限制条件有充分认识。
- 区分了大模型和小模型的概念。大模型的优势在于能够处理海量、非结构性的数据，并且给出“类人”性的回答，较好的给出了预测结果，拟合性好；但小模型更符合人的理解方式，简洁、历史悠久、经济学解释性程度高，但问题也显而易见就是精确性和稳健性不够。


##
这里之所以将经济学与计量经济学并列，是因为实证研究是现代经济学最主要的研究范式(Angrist et al., 2017)，而计量经济学是经济学实证研究最主要的方法论。随着数据可获得性的提升以及计算机技术的发展，经济学研究在过去40多年里发生了“实证革命”的范式变革，从原来以基于偏好、技术、禀赋、制度、行为等方面的基本假设的演绎推理为主的研究范式，转变为以数据为基础、运用计量经济学等方法推断经济因果关系的研究范式，这种研究范式就是实证研究。传统的案例分析也属于实证研究，但基于数据、运用计量经济学推断方法的实证研究，其科学性和严谨性得到了显著提升。大数据革命强化了经济学的实证研究范式(洪永淼和汪寿阳，2021a, 2021b)。

诺贝尔经济学奖获得者乔舒亚·安格里斯特(Joshua Angrist)认为，“应用计量经济学所考虑的问题和其他社会科学或者流行病学所考虑的问题并无本质上的区别。……任何希望从数据中得到有用推断的人都可称为应用计量经济学家”(安格里斯特和皮施克，2012，第2页)。

以ChatGPT为代表的通用生成式大模型技术的突破性进展，正在深刻重塑人类生产方式、生活方式、思维方式以及社会治理方式，也在深刻改变经济学的研究范式。长期以来，构建经济理论的基本方法论是经济学建模，即在一系列基本假设基础上，借助数学等逻辑工具进行演绎推理，研究少数关键的经济变量如何影响经济主体的行为与宏观经济的运行；与此相对应，计量经济学建模大都以简约模型为主，其中模型的函数形式大多给定，模型的未知参数维数不大，具有较强的经济可解释性。

人工神经网络是一个基于所谓“激活函数”(activation function)的非线性变换的数学模型，包含很多未知参数，这些参数可以通过数据进行估计(White, 1992)。计算机科学通常不称之为“参数估计”，而是称之为“模型训练”或“算法训练”。在统计学与数据科学中，“模型”一般是指给定函数形式且未知参数维数较低的参数模型(parametric model)，对未知参数维数很高且没有假设特定函数形式的一般数学模型，通常称为算法(Breiman, 2001)，也称为非参数模型(non-parametric model)。本文将一般意义上的数学模型(算法或非参数模型)和统计学意义上的参数模型统称为“模型”，并用“大模型”与“小模型”来区分它们。从计量经济学与统计学的视角看，人工神经网络是一种非参数统计模型。可以证明，当样本容量增加时，如果参数维数随之增加，则人工神经网络模型具备无限逼近满足一定正则条件的任何未知函数的能力，这一性质被称为人工神经网络的“泛逼近性质”(universal approximation property)。计量经济学家哈尔伯特·怀特(Halbert White)对人工神经网络模型做出了重要的原创性基础理论贡献(White, 1992)。人工神经网络是深度学习算法的基础模型。深度学习实际上是人工神经网络模型的多层非线性变换。简单的人工神经网络模型只包含一层非线性变换，这足以一致估计满足一定正则条件的任何未知的非线性函数。如果增加多层非线性变换(可多达几十层、几百层甚至几千层)，模型参数维数将呈指数式增长，模型复杂度越来越高，可以刻画复杂系统的许多精细结构，包括非线性、异质性与交互性等重要特征。这样深度学习的整体逼近能力比一般的人工神经网络有很大的提升。2017年，谷歌提出了一种名为变换器(transformer)的深度学习算法。深度学习的基础结构是一个大语言模型，输入为文本数据，输出也是文本数据。ChatGPT主要通过互联网公开大数据执行各种复杂任务。众所周知，大数据包括结构化数据和非结构化数据。结构化数据如GDP时间序列数据，每个季度有一个数值，可以用矩阵形式表示；而非结构化数据则不能用数字来表示，如文本数据，包括政府工作报告、上市公司财务报表、新闻媒介报道、微信微博聊天评论等。除文本数据外，非结构化数据还包括图像、音频与视频数据等，比如医院拍摄的X光照片、地球卫星拍摄的遥感图片，这些非结构化大数据包含了结构化数据所没有的大量有价值的信息。例如，语言是人们进行沟通交流、传递思想、表达情感的重要工具，因此，作为一种最主要的非结构化大数据，文本数据包含了经济主体的很多情感等心理信息。通过自然语言处理技术，可从文本数据中提取许多有用的心理信息，特别是构造可观测心理变量以进行定量分析。有人估计，非结构化数据占据了整个大数据的80%左右。与结构化数据相比，文本等非结构化数据都是高维数据，需要使用大模型进行分析，例如，大语言模型可用于精确分析文本数据的语法结构和上下文语义。

一个语言模型，如果只让它回答特定领域的问题，那么模型参数维数无需像ChatGPT这样的大语言模型那么多，可以大幅减少，这种模型相对于通用生成式大语言模型，可视为小模型。小模型就像是专门针对特定应用场景而开发出来的“偏科机器”，其“举一反三”即泛化能力相对不足。所谓“泛化”能力，是指基于某个特定数据训练的模型或算法，对未见到的新数据的预测能力。从统计学视角看，如果专注于某个领域的数据，那么这些数据具有较高的同质性，在这种情形下，模型无需过于复杂，模型参数维数不用太高，便可在某个特定领域达到不错的预测效果。

统计学与计量经济学长期面临的一个根本问题是所谓的“维数灾难”。在数据容量有限的条件下，模型未知参数维数越多，每个参数的估计越不精准，估计误差越大，这会导致模型过拟合，影响其泛化能力。统计学通常用均方误差(mean squared error)来测度预测的准确性。均方误差可分解为方差与偏差平方之和。因此，即使模型偏差很小，如果模型的未知参数数量非常多，其估计方差也会变得很大，导致预测不准确。统计学家与计量经济学家在选择模型时通常会考虑偏差与方差之间的平衡。事实上，计算机科学家通过计算机模拟仿真实验以及实际应用，发现了大模型在一定条件下会出现一种“双降”(double descent)现象，即当模型参数个数增加时，以均方误差衡量的预测误差先呈现出下降趋势，等模型复杂度达到一定临界点时，预测误差便会上升，这是统计学与计量经济学经典教科书介绍的U-型曲线。但是，当模型参数维数继续增加并达到另一个更高临界值时，模型预测误差会再次下降，虽然第二次下降的速度相比第一次下降的速度会缓慢很多，实证研究发现，模型参数维数的指数增长，才能换来预测误差的线性减少，这就是所谓的“双降”现象(Belkin et al., 2018; Nakkiran et al., 2021)。。“双降”现象打破了人们长期以来对模型复杂性的固化认知，它使大家逐步认识到，在通常的“小模型”空间之外，还有一个以前从未发现的“大模型”空间，那里呈现了与小模型完全不一样的规律性特征，特别是当模型复杂度跨过一个很大的临界值后，大模型便会呈现所谓的“涌现”能力，这种涌现能力与大模型的“双降”现象密切相关。

## ChatGPT与大模型对经济学研究范式的影响
### 理性经济人和人工智能经济人
新古典经济学的一个基本假设是理性经济人，即经济主体有一个目标函数，会利用一切可以利用的信息与资源，使自身利益最大化，这是一种理性行为。但是行为经济学研究表明，人类经济行为在很多情形下并不满足完全理性假设，存在着非理性因素与现象。赫伯特·西蒙(Herbert Simon)提出有限理性理论(bounded rationality)，并因此于1978年获得诺贝尔经济学奖。所谓有限理性，是指经济主体无法获取决策所需的所有信息，也不清楚问题的所有错综复杂的关系和行动后果，换言之，经济主体不仅收集处理数据能力有限，计算能力也有限。因此，Simon (1976)认为经济主体并非追求完全理性假设下的利益最大化，而是满意即可。西蒙的思想推动了行为经济学、行为金融学以及人工智能经济学的蓬勃发展。行为经济学、行为金融学主要研究经济主体的非理性行为及其对经济的影响，这些行为学科正在逐渐渗入到宏观经济学等其他学科(Akerlof, 2002; Angeletos and Huo, 2021; Angeletos and Lian, 2022; Angeletos et al., 2021; Hommes, 2021；那艺和贺京同, 2017)。

人工智能在很多方面可以辅助人的决策，例如，在高考领域，利用人工智能可以帮助更好选择高考志愿；
在学术研究中，可以利用ChatGPT辅助总结文献、准备PPT、编写程序、撰写论文等；
在量化交易中，利用算法预测市场走势，确定交易策略；
在企业管理中，人工智能可以帮助企业优化经营计划与提升管理效率。

### 孤立经济人与社会经济人

除了理性假设外，新古典经济学还假设经济人是孤立的，不考虑社会关系对经济人的经济行为的影响。在标准微观经济学教科书中，经典消费者理论只有一个消费者，在财务约束条件下实现效用最大化；厂商理论只有一个生产者，追求利润最大化或成本最小化。不管是消费者理论还是厂商理论，都是一个孤立的经济人，只对市场价格信号作出反应。

20世纪30年代，“凯恩斯革命”(Keynes, 1936)催生了宏观经济学。传统宏观经济学主要研究总量平衡，如总供给和总需求的平衡问题。新古典经济学将经济学优化理论与总量平衡分析方法结合起来(Ramsey, 1928; Cass, 1965; Koopmans, 1963)。例如，宏观经济学理论预期学派，假设一个具有完全理性预期的代表性经济人(如消费者或投资者)，在跨期财务约束条件下，选择一条最优消费与投资路径，使其一生总效用最大化。代表性经济主体的假设掩盖了现实经济中存在大量异质性经济主体的事实(如异质性偏好)，因此无法研究异质性经济主体的行为以及由此产生的异质性经济关系，如政策对异质性经济主体的不同影响。

在一个完全竞争性市场经济中，市场价格充分反映了各种市场信息，每一个经济人都是价格的接受者，只需要对市场价格信号作出反应，即可获得最优决策。但是，在现实经济中，除了经济人的异质性以外，经济人之间的决策行为甚至他们的目标函数都会互相影响。马克思指出，人是一切社会关系的总和。因此，现实经济中的经济人是社会经济人，其经济行为不仅受经济因素的影响，而且还受各种社会关系的影响，同时人的经济行为和经济因素也会影响其社会关系。传统制度主义经济学派早就提出“社会人”假设，认为人作为一种社会存在，除了追求经济利益之外，还有对安全、友情、尊重、归属等方面的社会需求；人的经济决策，必须建立在自身的经济条件、以及构成其社会生活重要组成部分的人际关系的基础之上。换言之，人的经济行为与其所处的社会环境密切相关，需要从个人与社会环境的相互关系去理解人的经济行为。

在金融学领域，一门交叉学科——社会金融学(social finance)正在兴起。社会金融学融合了金融学、经济学、社会学以及环境科学等多学科的知识，将传统金融工具和社会、环境目标相结合，旨在通过金融投资等工具帮助解决一系列伦理、社会与环境问题，推动人类经济社会可持续发展，并产生积极的社会影响。目前，环境与社会治理(ESG)已成为国内外经济学、金融学等学科的一个热门研究领域。

### 宏观经济学和微观经济学

“凯恩斯革命”催生了宏观经济学，从此经济学有了宏观经济学与微观经济学之分。宏观经济学研究整个国民经济的运行规律，特别是宏观经济变量之间的关系，如菲利普斯曲线(Phillips, 1958)、奥肯定律(Okun, 1970)以及泰勒规则(Taylor, 1993)等宏观经济定律。长期以来，宏观经济学与宏观计量经济学均是基于宏观经济变量进行建模，研究宏观经济变量之间的数量关系与逻辑关系，并据此解释宏观经济现象与预测宏观经济走向。这种经典宏观经济建模思想首先对微观经济数据进行加总，获得宏观经济变量，然后对宏观经济变量进行建模，其优点是可以得到简约模型，并具有较强的经济可解释性(Glandon et al., 2023)。此外，经济学家还将行为经济学特别是一些非理性因素引入宏观经济学分析框架之中(Akerlof, 2002, 2007)，克服宏观经济学理性预期学派只考虑理性预期这种理想情景的局限性，这在某种程度上回归到凯恩斯(Keynes, 1936)的“动物精神”和Shiller (2001, 2019)的“非理性繁荣”的分析框架。

### 定性分析与定量分析

众所周知，语言是人类进行信息沟通与情感交流的主要工具，因此文本数据包含结构化数据所没有的很多有价值信息，特别是经济主体对政策变化与外来冲击的心理反应，包括预期、情绪、情感等信息(洪永淼等，2023)。Shiller (2019)指出，相对于结构化经济数据，文本数据包含很多关于经济运行与经济发展的丰富信息。因此，从文本数据提取各类经济主体心理信息便成为一种有效方式，这种方法比传统的心理数据构造方法(如信心与预期统计调查数据、心理学实验测度法)具有不少优势，特别是在样本代表性和抽样频率等方面。从文本数据提取心理因素的主要工具是自然语言处理技术，目前经济学与其他社会科学常用的方法包括词频法，词袋法，主题法等(Gentzkow and Kelly，2019)。通过文本数据测度心理变量，打破了定性分析和定量分析的界限，使原来只能进行定性分析的很多经济学问题，转变成可以进行定量分析。目前，从文本数据提取经济主体心理信息的常用方法简单可行，但也存在一些缺陷，如所构建的心理变量大多存在不可忽视的测度误差，这些测度误差在回归分析时可能会造成估计偏差(洪永淼等，2023)。而且，目前几乎所有基于文本数据的心理变量测度都是通过加总而得，很多微观层面的心理异质性消失了。举一个简单例子，如果在一个文本数据中，一半的人是悲观情绪，另一半的人是乐观情绪，则基于关键词加总而得到的情绪指数可能在整体上既不表示悲观也不表示乐观，原有的异质性情绪消失了。在这方面，基于互联网海量文本数据训练的ChatGPT可用于构建微观层面(如每个消费者、投资者)的心理变量，避免由于加总而导致异质性心理信息的损失。ChatGPT是目前自然语言处理领域最先进的技术，可借助其拥有的几乎整个互联网信息与知识，比较准确解读文本数据的语法结构与上下文语义，从而比较准确从文本数据中提取心理信息。

### 小模型范式和大模型范式

经济理论构建大都通过经济学建模。经济学建模的基本方法论是:基于偏好、技术、资源、禀赋、制度、行为(如预期)等假设，借助数学等逻辑工具的演绎推理，研究少数关键经济因素对经济主体决策与宏观经济运行的影响。在建模过程中聚焦少数主要经济变量而忽略其他次要因素的影响(通过假设其他因素不变)，既是数学抽象的必然要求，也是保障模型的经济可解释性的有效方法。正如列宁(1990，第142页)所指出的，“物质的抽象，自然规律的抽象，价值的抽象以及其他等等，一句话，一切科学的(正确的、郑重的、非瞎说的)抽象，都更深刻、更正确、更完全地反映着自然”。然而，从预测角度看，一个具有很强经济可解释性的简约经济学模型，其预测能力不一定精准。一个主要原因是影响现实经济社会活动的因素成千上万，繁多复杂。

无论是统计学还是计量经济学，这些方法论之争背后都蕴藏着相同的思想，即获得一个既有较好经济可解释性又有较强泛化能力的简约模型。在统计学与计量经济学，获得简约模型的主要方法是降维。常用的经典降维方法有主成分分析法、因子模型、AIC和BIC等模型选择准则、投影寻踪回归(projection pursuit regression)与单指标模型(single index model)等，所选择的最佳模型通常具有较低的复杂度和较强的预测能力。此外，也可通过经济理论约束条件进行降维，例如经济主体具有风险厌恶的特征，则其效用函数必定是凹函数。又如，如果市场有效性假说成立，那么所有历史信息都无法预测未来的回报率，因此预测模型的滞后项预测变量的系数都应该为零，这样可帮助简化模型。


大量实证研究(Kelly and Xiu，2023)表明，在预测经济与金融市场变化趋势方面，机器学习在很大程度上改进了传统计量经济学模型，但其预测准确性尚未达到令人满意的程度。

### 现实复杂，但模型只能捕捉少数

一个根本原因是人类经济社会系统是一个高度复杂系统，受到成千上万的相互关联的变量的影响，涉及政治、经济、社会、法律、政策、技术、历史、文化、心理、环境等各种因素。

与自然界不同，经济系统受人类心理影响大，而人类心理本身存在很大的不确定性。经济主体在面临不确定性时通常形成一种预期，如果预期过高或过低，就会产生悲观或乐观的情绪。这样的情绪会影响人们的经济行为，如影响投资选择和消费倾向等。客观存在的经济社会活动影响人类心理，而人类心理反过来又会影响经济主体的行为与经济社会系统的运行，这种心理影响称为“反身性”。此外，经济主体存在明显的异质性，如不同所有制的企业，不同收入水平的消费者，其行为特征包括对经济政策与外生性冲击的反应以及所受到的影响是不一样的。最后，由于偏好、技术、环境、人口、政策与制度等变化，经济系统具有时变性，时变性可以是突变，也可以是缓慢变化。反身性、异质性、交互性以及时变性对预测未来会产生重大影响。为了显著改进经济金融预测，可以考虑大模型范式。由于其灵活性，大模型可以容纳互相关联的高维变量，刻画经济主体的异质性、变量之间的非线性与交互性，以及模型参数的时变性，从而大幅度降低模型误差，提高预测精准度。

### 计算机算法与计算经济学
。例如，计算经济学一个著名的模型是可计算一般均衡模型。早在19世纪70年代，经济学“边际革命”代表人物之一莱昂·瓦尔拉斯(Walras，1874)便提出了一般均衡论，Wald (1936)给出一般均衡存在的第一个数学证明，后来Arrow and Debreu (1874)提供了更为严格的证明。这些证明将一般均衡的存在性视为一个不动点问题，然后运用数学不动点定理给予证明。这些数学证明建立了严谨的一般均衡理论，但并没有给出如何求解一般均衡价格的方法。Scarf (1967)开创性提出的不动点算法，能够将不动点计算出来，这不仅推动经济数学的发展，也奠定可计算一般均衡理论的坚实基础，使一般均衡论具有广泛的实际应用价值。可计算一般均衡模型常用于政策评估。这个方法综合应用经济学、仿生学和计算机技术(特别是算法)来研究经济主体的行为特征与复杂经济系统的运行规律，其中一个著名例子是基于行为主体的模型(agent-based model，ABM)，这个模型使用计算机模拟仿真技术，研究遵从简单规则的大量经济主体的行为如何产生复杂的宏观经济特征(如泡沫)。

## 人工智能与ChatGPT 的局限性
，人脑是一个非常高效甚至优雅的系统，只需要少量信息即可运作；它不推断数据点之间的直接关联，而是创造解释。”

，经济学实证研究最主要的目的是因果推断。长期以来，人类的思维方式一直是通过逻辑推断，特别是因果推断，来认识世界和改造世界。所谓因果推断，是指在控制所有其他解释变量不变的条件下，观察某一解释变量的变化是否会引起因变量的变化。

人工智能可以用于因果推断(Athey, 2019; Athey and Imbens, 2019)。由于其出色的泛化能力，人工智能能够比较精确地估测虚拟事实，从而显著提升因果推断与政策评估的有效性与精准性。但是，大数据特别是经济大数据几乎都是观测数据，包括大模型在内的人工智能算法事实上是统计学方法，而基于观测数据、运用统计学与计量经济学方法进行因果推断本质上是一种统计关系推断(Leamer, 1983)。这种统计关系需要在增加很多额外假设的条件下才可以被解释为经济学因果关系。

要识别经济学因果关系，不能仅仅依靠基于计量经济学与人工智能的因果推断方法，还必须引入实验经济学(如随机控制实验)等方法。如果要将基于观测数据的人工智能因果关系解释为经济学因果关系，则需要经济理论的指导，而且，这种因果关系解释也只是一种可能性，即人工智能因果关系与经济学因果关系是相容的或不互相排斥，但并不意味人工智能因果关系就一定是经济学因果关系。

人工智能特别是大模型正在推动经济学与社会科学研究范式的变革，特别是从模型驱动范式到数据驱动范式的转变，但仍需要与经济理论相结合，增强算法的经济可解释性。

任何模型都是建立在各种假设基础上，模型驱动范式所获得的结论很可能具有模型依赖性，致使不同模型可能导致不同的结论(Breznau et al., 2022)。这就是为什么那么多经济学实证研究都要考虑所谓的稳健性检验(robustness check)，即检验在不同的模型条件下是否能够得到相同或类似的结论。。相反地，数据驱动范式试图通过使用与具体模型无关的算法，通过算法直接从数据中获得经济变量之间的逻辑关系，以得到与具体模型无关的稳健结论。但是，数据驱动范式所依赖的算法特别是大模型，大多是“黑箱”，缺乏经济可解释性，这是人工智能特别是大模型最大的一个弱点。数据驱动范式必须与经济理论相结合，才能拥有经济可解释性。因此，数据驱动模式可获得比较稳健的结论，但它并不能取代经济理论的指导。

人工智能和以ChatGPT为代表的大模型没有改变经济学乃至社会科学实证研究的本质特征，即**从样本推断总体性质的归纳范式。**人工智能特别是大模型强化了以数据为基础的实证研究范式，但这种人工智能归纳推理在实践中依然可能会出现错误，类似于统计学的第一类错误和第二类错误(洪永淼，2021)。

人工智能以及ChatGPT等大模型所使用的数据是来源于互联网的开源数据。互联网开源数据中存在大量不真实和虚假的信息，也包含很多违背当今社会伦理与道德规范的内容，还可能出现样本选择偏差的情况。

1.**样本选择偏差**。如果有关某个事件的文本数据只有少数几篇文章，而这些文章根本无法代表社会大多数人的观点，只能代表少数人的意见，当人工智能分析这些数据时，很可能会将这些个别人的意见视为是代表性意见，导致偏见甚至“幻觉”的出现。互联网大数据也可能存在“样本选择偏差”问题，如“数字鸿沟”导致的样本偏差。互联网大数据无法反映不上网或很少上网的群体的经济行为信息，这个群体可能包括了年长者、西部地区和农村地区的群众，数字鸿沟在这些情况下是不可避免的。
2.**数据风险**。由于数据质量原因而产生的风险，可称为数据风险。随着数字经济的蓬勃发展，数据成为关键的生产要素，因此必须防范由于数据可靠性问题而引起的数据风险。数据可靠性与数据质量是约束包括大模型在内的人工智能可靠性的最基本因素。
3.除了大数据可靠性问题引起的数据风险外，还存在由于模型或算法本身的泛化能力问题而产生的**模型风险或算法风险**。造成模型风险或算法风险的原因很多，包括大模型的训练算法与训练时间、算法本身的有效性等，但最主要的一个原因是数据漂移(data drift)和模型漂移(model drift)所引起的模型或算法泛化能力下降的问题。

**技术进步、人口结构变化、偏好变化、政策变化以及诸如新冠疫情大流行和地缘政治军事冲突等重大外生冲击，都会引起经济主体的预期与行为的变化，从而导致经济结构与经济关系发生变化。上述变化首先会引起大数据的分布变化，这种变化可能是突变式的，也可能是渐进式的，或者两者兼之。**例如，在文本数据中，随着经济社会快速变化与发展，很多新的网络语言不断出现，而一些旧网络词语也会被赋予新含义，从计量经济学与统计学视角看，这些互联网文本数据具有显著的时变性或不平稳性，这种数据时变性称为数据漂移。除了引起数据漂移之外，技术、人口、偏好、政策变化以及外生冲击等因素还会引起经济变量之间的关系发生变化。由于模型或算法是基于已知数据特别是历史数据进行训练，模型无法刻画经济关系的新变化，从而影响模型或算法的泛化能力，这种现象称为模型漂移。

我们正处于大经济、大科技、大数据、大模型的新时代。
数字技术革命与新一轮工业革命对人类**生产方式、生活方式与思维方式**产生重大变革，也在深刻改变**社会治理**方式。数字经济特别是大科技平台等新经济形态的出现，与中国超大经济规模的优势相结合，催生了新的经济运行模式与运行规律。。挖掘、处理、分析海量大数据的主要工具是人工智能技术。

**长期以来，经济学理论构建与创新主要是通过经济学建模与计量经济学建模。经济学建模大多建立在关于偏好、技术、人口、资源、制度、行为等因素的假设基础之上，通过数学等逻辑工具的演绎推理，聚焦少数关键经济变量，研究经济主体行为与经济运行规律。这种小模型范式能够聚焦所研究问题的最本质的特征与内在联系，模型的经济可解释性也比较强。**

由于人类经济社会系统是一个高度复杂系统，其影响因素成千上万，且它们之间的关系错综复杂，并且具有显著的异质性、交互性、非线性、时变性等特征。

长期以来，经济学与计量经济学的实证研究几乎只使用小模型。在大数据与人工智能时代，应该尝试大模型范式，探索以ChatGPT为代表的大模型对经济学研究范式可能带来的影响。应当指出，强调大模型并不意味着小模型就不重要。我们应该将小模型范式和大模型范式辩证统一起来，以获得对复杂经济社会系统运行规律的深刻认识。